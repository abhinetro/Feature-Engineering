{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "EpylNk8xrFJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What is a parameter?\n",
        "A **parameter** is an internal characteristic of a machine learning model that is learned from the training data. For example, in linear regression, the slope and intercept (weights) are parameters.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. What is correlation?\n",
        "**Correlation** is a statistical measure that expresses the extent to which two variables are linearly related. It ranges from -1 to +1.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. What does negative correlation mean?\n",
        "**Negative correlation** means that as one variable increases, the other decreases. For example, as temperature increases, the sale of heaters decreases.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "**Machine Learning** is a subset of AI that enables systems to learn from data and improve performance without being explicitly programmed.\n",
        "\n",
        "**Main components:**\n",
        "- Data\n",
        "- Model\n",
        "- Loss Function\n",
        "- Optimizer\n",
        "- Evaluation Metrics\n",
        "\n",
        "---\n",
        "\n",
        "## 5. How does loss value help in determining whether the model is good or not?\n",
        "The **loss value** represents the error between predicted and actual output. A lower loss indicates a better performing model.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. What are continuous and categorical variables?\n",
        "- **Continuous variables** are numerical and can take any value (e.g., height, weight).\n",
        "- **Categorical variables** represent categories (e.g., gender, city).\n",
        "\n",
        "---\n",
        "\n",
        "## 7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "**1. Label Encoding**\n",
        "- How it works: Converts each category to a number.\n",
        "\n",
        "  - Example: {Male: 0, Female: 1}\n",
        "\n",
        "- Use when: The categorical variable is ordinal (e.g., Low < Medium < High).\n",
        "\n",
        "- Pros: Simple, compact.\n",
        "\n",
        "- Cons: Implies an order even if there isn't one — not ideal for nominal variables.\n",
        "\n",
        "**2. One-Hot Encoding**\n",
        "- How it works: Creates a new binary column for each category.\n",
        "\n",
        "  - Example: City = Delhi, Mumbai, Kolkata →\n",
        "\n",
        "    - Delhi: [1, 0, 0]\n",
        "\n",
        "    - Mumbai: [0, 1, 0]\n",
        "\n",
        "- Use when: The variable is nominal (no inherent order).\n",
        "\n",
        "- Pros: No assumptions about ordering.\n",
        "\n",
        "- Cons: Can lead to high dimensionality if many unique categories (the \"curse of dimensionality\").\n",
        "\n",
        "**3. Ordinal Encoding**\n",
        "- Similar to Label Encoding but explicitly assigns numbers based on a known order.\n",
        "\n",
        "  - Example: Low = 1, Medium = 2, High = 3\n",
        "\n",
        "- Use when: You have ordinal data.\n",
        "\n",
        "**4. Binary Encoding**\n",
        "- Converts categories to binary numbers and then splits into separate columns.\n",
        "\n",
        "  - E.g., Category A = 1 → 001, B = 2 → 010\n",
        "\n",
        "- Pros: Less dimensionality than one-hot encoding.\n",
        "\n",
        "- Use when: You have many categories but want to keep dimensionality low.\n",
        "\n",
        "**5. Target Encoding (Mean Encoding)**\n",
        "- Replaces each category with the mean of the target variable for that category.\n",
        "\n",
        "  - Example (in a regression task): If \"City\" = Mumbai usually has house prices = ₹50L, encode \"Mumbai\" as 50.\n",
        "\n",
        "- Use when: You have many categories and are doing supervised learning.\n",
        "\n",
        "- Caution: Can lead to overfitting.\n",
        "\n",
        "**6. Frequency or Count Encoding**\n",
        "- Replace each category with its frequency/count.\n",
        "\n",
        "  - E.g., if \"Male\" appears 100 times, encode as 100.\n",
        "\n",
        "- Use when: Simplicity is preferred, or as a baseline.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. What do you mean by training and testing a dataset?\n",
        "- **Training** dataset is used to teach the model.\n",
        "- **Testing** dataset evaluates model performance on unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. What is sklearn.preprocessing?\n",
        "**sklearn.preprocessing** is a module in Scikit-learn that provides functions and classes to prepare your data for machine learning models.\n",
        "\n",
        "Raw data is often messy — with missing values, inconsistent scales, or categorical variables. The preprocessing module helps transform it into a format that ML algorithms can use effectively.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. What is a Test set?\n",
        "A **test set** is a portion of the dataset not seen by the model during training and used only to assess its final performance.\n",
        "\n",
        "---\n",
        "\n",
        "## 11. How do we split data for model fitting (training and testing) in Python?\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [1, 4, 9, 16, 25]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 12. How do you approach a Machine Learning problem?\n",
        "1. Understand the problem\n",
        "2. Collect and clean data\n",
        "3. Perform EDA (Exploratory Data Analysis)\n",
        "4. Preprocess data\n",
        "5. Select and train model\n",
        "6. Evaluate and tune\n",
        "7. Deploy\n",
        "\n",
        "---\n",
        "\n",
        "## 13. Why do we have to perform EDA before fitting a model to the data?\n",
        "**1. Understand the Data**\n",
        "- Know what you're working with: types of variables, distributions, data types, etc.\n",
        "- Helps identify target and feature relationships.\n",
        "\n",
        "**2. Identify Missing or Incorrect Values**\n",
        "- Models don’t like missing or weird values (like 'N/A', 0, '??').\n",
        "- EDA helps you spot and handle them before training.\n",
        "\n",
        "**3. Detect Outliers**\n",
        "- Outliers can skew your model's predictions, especially in linear models.\n",
        "- Visual tools like box plots help catch them.\n",
        "\n",
        "**4. Visualize Distributions & Relationships**\n",
        "- Use histograms, pair plots, heatmaps to understand feature distributions and correlations.\n",
        "\n",
        "**5. Feature Engineering Ideas**\n",
        "- EDA often reveals patterns that help create new features or transform existing ones.\n",
        "- E.g., binning ages, log-transforming skewed data, etc.\n",
        "\n",
        "**6. Choose the Right Model & Preprocessing**\n",
        "- Some models require scaling (e.g., SVM), others don’t.\n",
        "- If variables are highly correlated, you might choose to drop or combine them.\n",
        "\n",
        "**7. Avoid Garbage-In, Garbage-Out**\n",
        "- If the data is messy and misunderstood, the model will give poor results — no matter how advanced it is.\n",
        "\n",
        "---\n",
        "\n",
        "## 14. How can you find correlation between variables in Python?\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
        "correlation_matrix = df.corr()\n",
        "correlation_matrix\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 15. What is causation? Explain difference between correlation and causation with an example.\n",
        "- **Causation** means one event causes another.\n",
        "- **Correlation** is a mutual relationship but doesn't imply causation.\n",
        "\n",
        "Example:\n",
        "- Correlation: Ice cream sales and drowning deaths increase together.\n",
        "- Causation: Hot weather increases both independently.\n",
        "\n",
        "---\n",
        "\n",
        "## 16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "An **optimizer** minimizes the loss function.\n",
        "\n",
        "Common types:\n",
        "- **SGD (Stochastic Gradient Descent)**: updates weights using a few samples.\n",
        "- **Adam**: combines momentum and adaptive learning rate.\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 17. What is sklearn.linear_model?\n",
        "**sklearn.linear_model** is a module in Scikit-learn that provides linear models for regression and classification.\n",
        "\n",
        "It includes some of the most widely used algorithms in machine learning, like Linear Regression, Logistic Regression, Ridge, Lasso, and more.\n",
        "\n",
        "---\n",
        "\n",
        "## 18. What does model.fit() do? What arguments must be given?\n",
        "**model.fit()** is the method that trains your machine learning model. It takes your features (X) and target/labels (y) and learns the patterns in the data.\n",
        "\n",
        "```python\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "Arguments:\n",
        "  - Features (X)\n",
        "  - Target (y)\n",
        "\n",
        "---\n",
        "\n",
        "## 19. What does model.predict() do? What arguments must be given?\n",
        "**model.predict()** is used after training a model with **fit()**. It takes new input data (X) and uses the learned patterns to make predictions (outputs).\n",
        "```python\n",
        "predictions = model.predict(X_test)\n",
        "```\n",
        "Arguments:\n",
        "  - Features to predict on\n",
        "\n",
        "---\n",
        "\n",
        "## 20. What is feature scaling? How does it help in Machine Learning?\n",
        "Feature scaling is the process of transforming your features (input variables) so that they’re all on a similar scale — usually to avoid some features dominating others just because of their magnitude.\n",
        "\n",
        "For example:\n",
        "\n",
        "- Height in cm: [150, 170, 180]\n",
        "\n",
        "- Salary in INR: [20,000, 60,000, 1,00,000]\n",
        "\n",
        "Even though both are important, salary will dominate due to its larger scale. That’s where scaling helps.\n",
        "\n",
        "It help in Machine Learning to:\n",
        "- Improves performance of models that are sensitive to scale:\n",
        "  - K-Nearest Neighbors (KNN)\n",
        "\n",
        "  - Support Vector Machines (SVM)\n",
        "\n",
        "  - Gradient Descent-based algorithms\n",
        "\n",
        "  - Principal Component Analysis (PCA)\n",
        "\n",
        "- Makes training faster & more stable (especially for neural nets and optimization-based models).\n",
        "\n",
        "- Better visualization when plotting features.\n",
        "\n",
        "---\n",
        "\n",
        "## 21. How do we perform scaling in Python?\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_X = scaler.fit_transform([[1, 2], [3, 4], [5, 6]])\n",
        "scaled_X\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 22. Explain data encoding?\n",
        "**Data encoding** is converting categorical data to numerical form so that it can be used by ML algorithms.\n",
        "\n",
        "Types:\n",
        "- Label Encoding\n",
        "- One-Hot Encoding\n",
        "- Binary Encoding\n",
        "\n",
        "```python\n",
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(['cat', 'dog', 'dog', 'mouse'])\n",
        "labels\n",
        "```"
      ],
      "metadata": {
        "id": "P1oIufoyrPgZ"
      }
    }
  ]
}